import logging
import os
import time
import tempfile
import base64
import io
from datetime import datetime
from typing import Optional
from google import genai
from google.genai import types
import fal_client

from app.core.config import config
from app.utils.media_uploader import media_uploader

logger = logging.getLogger(__name__)


class VideoGenerationService:
    """Consolidated service for all video generation - ALL models in one file"""

    def __init__(self):
        """Initialize Gemini and FAL.ai clients for video generation"""
        # Gemini for Veo models
        if config.GEMINI_API_KEY:
            self.gemini_client = genai.Client(
                http_options={"api_version": "v1beta"},
                api_key=config.GEMINI_API_KEY
            )
        else:
            self.gemini_client = None
        
        # FAL.ai for Pixverse models
        if config.FAL_API_KEY:
            os.environ["FAL_KEY"] = config.FAL_API_KEY
            fal_client.api_key = config.FAL_API_KEY
        
        # Media uploader for storage
        self.uploader = media_uploader

    async def generate_video(
        self,
        prompt: str,
        model: str,
        mode: str,
        user_id: str,
        shape: str = "landscape",
        image_file: Optional[bytes] = None,
        image_filename: Optional[str] = None
    ) -> str:
        """
        Main entry point - Generate video based on model and mode

        Args:
            prompt: Text prompt for video generation
            model: Model name (veo-2, veo-3-fast)
            mode: 'generate' for text-to-video, 'edit' for image-to-video
            user_id: User ID
            shape: Video aspect ratio (square, portrait, landscape)
            image_file: Image bytes for image-to-video mode
            image_filename: Image filename

        Returns:
            Video URL (GCS or local)
        """
        try:
            if mode == "generate":
                return await self._generate_from_text(prompt, model, user_id, shape)
            elif mode == "edit":
                if not image_file:
                    raise ValueError("Image file required for edit mode")
                return await self._generate_from_image(prompt, model, user_id, shape, image_file, image_filename)
            else:
                raise ValueError(f"Invalid mode: {mode}")
        except Exception as e:
            logger.error(f"Error in video generation: {str(e)}")
            raise

    # ==================== TEXT-TO-VIDEO GENERATION ====================

    async def _generate_from_text(self, prompt: str, model: str, user_id: str, shape: str) -> str:
        """Generate video from text using any model"""
        logger.info(f"Generating video with {model}: {prompt[:50]}...")
        
        # Map shape to aspect ratio (portrait or landscape only)
        aspect_ratio = "9:16" if shape.lower() == "portrait" else "16:9"
        
        # Determine model type and generate
        
        if model == "veo-2":
            # Gemini Veo 2.0
            video_config = types.GenerateVideosConfig(
                aspect_ratio=aspect_ratio,
                number_of_videos=1,
                duration_seconds=8,
                person_generation="ALLOW_ALL"
            )
            
            operation = self.gemini_client.models.generate_videos(
                model="veo-2.0-generate-001",
                prompt=prompt,
                config=video_config
            )
            
            while not operation.done:
                logger.info(f"Video generation with {model} in progress...")
                time.sleep(10)
                operation = self.gemini_client.operations.get(operation)
            
            result = operation.result
            if not result or not result.generated_videos:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_gemini_video(result.generated_videos[0], prompt, user_id, model)
        
        elif model == "veo-3-fast":
            # Gemini Veo 3.0 Fast
            video_config = types.GenerateVideosConfig(
                aspect_ratio=aspect_ratio,
                number_of_videos=1,
                duration_seconds=8,
                person_generation="ALLOW_ALL"
            )
            
            operation = self.gemini_client.models.generate_videos(
                model="veo-3.0-fast-generate-001",
                prompt=prompt,
                config=video_config
            )
            
            while not operation.done:
                logger.info(f"Video generation with {model} in progress...")
                time.sleep(10)
                operation = self.gemini_client.operations.get(operation)
            
            result = operation.result
            if not result or not result.generated_videos:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_gemini_video(result.generated_videos[0].video, prompt, user_id, model, direct=True)
        
        elif model == "pixverse":
            # Pixverse text-to-video
            handler = fal_client.submit(
                "fal-ai/pixverse/v5/text-to-video",
                arguments={
                    "prompt": prompt,
                    "aspect_ratio": aspect_ratio,
                    "seed": 42
                }
            )
            
            result = handler.get()
            if not result or "video" not in result or not result["video"]:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_fal_video(result["video"]["url"], prompt, user_id, model)
        
        else:
            raise ValueError(f"Model {model} not supported for text-to-video generation")

    # ==================== IMAGE-TO-VIDEO GENERATION ====================

    async def _generate_from_image(
        self,
        prompt: str,
        model: str,
        user_id: str,
        shape: str,
        image_file: bytes,
        image_filename: str
    ) -> str:
        """Generate video from image using any model"""
        logger.info(f"Image-to-video generation with {model}: {prompt[:50]}...")
        
        # Map shape to aspect ratio (portrait or landscape only)
        aspect_ratio = "9:16" if shape.lower() == "portrait" else "16:9"
        
        if model == "pixverse-image-to-video":
            # Resize image if needed
            resized_content = self._resize_image_if_needed(image_file)
            
            # Convert to base64
            image_base64 = base64.b64encode(resized_content).decode('utf-8')
            
            # Determine content type from filename
            content_type = "image/jpeg"
            if image_filename.lower().endswith('.png'):
                content_type = "image/png"
            elif image_filename.lower().endswith('.webp'):
                content_type = "image/webp"
            
            image_data_url = f"data:{content_type};base64,{image_base64}"
            
            handler = fal_client.submit(
                "fal-ai/pixverse/v5/image-to-video",
                arguments={
                    "prompt": prompt,
                    "duration": "5",
                    "aspect_ratio": aspect_ratio,
                    "cfg_scale": 0.5,
                    "negative_prompt": "blur, distort, and low quality",
                    "num_videos": 1
                }
            )
            
            result = handler.get()
            if not result or "video" not in result or not result["video"]:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_fal_video(result["video"]["url"], prompt, user_id, model)
        
        elif model == "kling-image-to-video":
            # Kling image-to-video
            resized_content = self._resize_image_if_needed(image_file)
            image_base64 = base64.b64encode(resized_content).decode('utf-8')
            
            content_type = "image/jpeg"
            if image_filename.lower().endswith('.png'):
                content_type = "image/png"
            elif image_filename.lower().endswith('.webp'):
                content_type = "image/webp"
            
            image_data_url = f"data:{content_type};base64,{image_base64}"
            
            handler = fal_client.submit(
                "fal-ai/kling-video/v2.1/master/image-to-video",
                arguments={
                    "prompt": prompt,
                    "image_url": image_data_url,
                    "duration": "5",
                    "aspect_ratio": aspect_ratio,
                    "cfg_scale": 0.5,
                    "num_videos": 1
                }
            )
            
            result = handler.get()
            if not result or "video" not in result or not result["video"]:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_fal_video(result["video"]["url"], prompt, user_id, f"{model}_img2vid")
        
        elif model == "wan-2.2":
            # WAN 2.2 image-to-video
            dimension_mapping = {
                "square": {"width": 512, "height": 512},
                "portrait": {"width": 512, "height": 768},
                "landscape": {"width": 768, "height": 512}
            }
            dimensions = dimension_mapping.get(shape, {"width": 768, "height": 512})
            
            resized_content = self._resize_image_if_needed(image_file)
            image_base64 = base64.b64encode(resized_content).decode('utf-8')
            
            content_type = "image/jpeg"
            if image_filename.lower().endswith('.png'):
                content_type = "image/png"
            elif image_filename.lower().endswith('.webp'):
                content_type = "image/webp"
            
            image_data_url = f"data:{content_type};base64,{image_base64}"
            
            handler = fal_client.submit(
                "fal-ai/wan/v2.2-a14b/image-to-video",
                arguments={
                    "prompt": prompt,
                    "image_url": image_data_url,
                    "width": dimensions["width"],
                    "height": dimensions["height"],
                    "duration": 5,
                    "fps": 24,
                    "num_videos": 1,
                    "guidance_scale": 7.5,
                    "num_inference_steps": 25
                }
            )
            
            result = handler.get()
            if not result or "video" not in result or not result["video"]:
                raise Exception(f"No video generated by {model}")
            
            return await self._download_fal_video(result["video"]["url"], prompt, user_id, f"{model}_img2vid")
        
        else:
            raise ValueError(f"Model {model} not supported for image-to-video generation")

    # ==================== HELPER METHODS ====================

    def _resize_image_if_needed(self, image_content: bytes, max_dimension: int = 4000) -> bytes:
        """Resize image if needed (delegates to media_uploader)"""
        return self.uploader.resize_image_if_needed(image_content, max_dimension)

    async def _download_gemini_video(self, video_obj, prompt: str, user_id: str, model: str, direct: bool = False) -> str:
        """Download video from Gemini and upload to GCS"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_prompt = "".join(c for c in prompt[:30] if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_prompt = safe_prompt.replace(' ', '_')
            model_prefix = model.replace("-", "_").replace(".", "_")
            filename = f"{model_prefix}_{timestamp}_{safe_prompt}.mp4"
            
            # Download to temp file
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
            tmp_path = tmp.name
            tmp.close()
            
            if direct:
                # For direct video object
                self.gemini_client.files.download(file=video_obj)
                video_obj.save(tmp_path)
            else:
                # For generated_video object
                self.gemini_client.files.download(file=video_obj.video)
                video_obj.video.save(tmp_path)
            
            # Read bytes and upload
            with open(tmp_path, 'rb') as f:
                video_bytes = f.read()
            
            video_url = await self.uploader.upload_bytes(video_bytes, filename, user_id, 'video/mp4', 'video')
            
            # Cleanup
            try:
                os.unlink(tmp_path)
            except:
                pass
            
            return video_url
            
        except Exception as e:
            logger.error(f"Error downloading Gemini video: {str(e)}")
            raise

    async def _download_fal_video(self, video_url: str, prompt: str, user_id: str, model: str) -> str:
        """Download video from FAL.ai URL and upload to GCS"""
        try:
            model_prefix = model.replace("-", "_")
            return await self.uploader.upload_video_from_url(video_url, prompt, user_id, "landscape", model_prefix)
            
        except Exception as e:
            logger.error(f"Error downloading FAL video: {str(e)}")
            raise


# Create singleton instance
video_generation_service = VideoGenerationService()
